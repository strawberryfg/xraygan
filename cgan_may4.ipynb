{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "cgan_may4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNGhkhe2HmMyjqWFh3auz1a"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcFVv_C2tkWT"
      },
      "source": [
        "# mount drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfVK1rDXthsp",
        "outputId": "e7b05bd0-3b93-4b48-9c32-80fcec1e7e4b"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "os.chdir(\"drive/MyDrive/xray GAN/\")\n",
        "os.listdir"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function posix.listdir>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCZ8LM0mlka6"
      },
      "source": [
        "# imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJP0YY_pliE1"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
        "from keras.layers import BatchNormalization, Activation, ZeroPadding2D, Embedding, Multiply, Concatenate, concatenate\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import multiply\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from os import path as osp\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from sklearn import preprocessing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9csIzazlvYs"
      },
      "source": [
        "# CGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gm9JhqHqq5kC",
        "outputId": "9fb879e3-e06e-4101-aef6-4b81eee013a0"
      },
      "source": [
        "pip install jdc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting jdc\n",
            "  Downloading https://files.pythonhosted.org/packages/5a/cb/9afea749985eef20f3160e8826a531c7502e40c35a038dfe49b67726e9a0/jdc-0.0.9-py2.py3-none-any.whl\n",
            "Installing collected packages: jdc\n",
            "Successfully installed jdc-0.0.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihEacl9Wr1zx"
      },
      "source": [
        "import jdc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8UV0g6LnqZe"
      },
      "source": [
        "class CGAN(): \n",
        "  def __init__(self):\n",
        "    #self.__root = None\n",
        "    # Input shape\n",
        "    self.img_rows = 256\n",
        "    self.img_cols = 256\n",
        "    self.channels = 1\n",
        "    self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
        "    self.num_classes = 5\n",
        "    self.latent_dim = 128\n",
        "\n",
        "    optimizer = Adam(0.0002, 0.5)\n",
        "\n",
        "    # Build and compile the discriminator\n",
        "    self.discriminator = self.build_discriminator()\n",
        "  \n",
        "    self.discriminator.compile(loss='binary_crossentropy',\n",
        "                                  optimizer=optimizer,\n",
        "                                  metrics=['accuracy'])\n",
        "\n",
        "    # Build the generator\n",
        "    self.generator = self.build_generator()\n",
        "\n",
        "    # The generator takes noise as input and generates imgs\n",
        "    noise = Input(shape=(self.latent_dim,))\n",
        "    label = Input(shape=(1,))\n",
        "\n",
        "    img = self.generator([noise, label])\n",
        "    # For the combined model we will only train the generator\n",
        "    self.discriminator.trainable = False\n",
        "\n",
        "    # The discriminator takes generated images as input and determines validity\n",
        "    valid = self.discriminator([img, label])\n",
        "\n",
        "    # The combined model  (stacked generator and discriminator)\n",
        "    # Trains the generator to fool the discriminator\n",
        "    self.combined = Model([noise, label], valid)\n",
        "    self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)   \n",
        "\n",
        "  def build_generator(self):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(128 * 32 * 32, activation=\"relu\", input_dim=self.latent_dim))\n",
        "    model.add(Reshape((32, 32, 128)))\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(Conv2D(32, kernel_size=3, padding=\"same\"))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(self.channels, kernel_size=3, padding=\"same\"))\n",
        "    model.add(Activation(\"tanh\"))\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    noise = Input(shape=(self.latent_dim,))\n",
        "    label = Input(shape=(1,), dtype='int32')\n",
        "    label_embedding = Flatten()(Embedding(self.num_classes, self.latent_dim)(label))\n",
        "    model_input = multiply([noise, label_embedding])\n",
        "    img = model(model_input)\n",
        "\n",
        "    return Model([noise, label], img)\n",
        "  \n",
        "  def build_discriminator(self):\n",
        "    img = Input(shape=self.img_shape)\n",
        "    label = Input(shape=(1,), dtype='float32')\n",
        "    c1 = Conv2D(32, kernel_size=3, strides=2, padding=\"same\")(img)\n",
        "    lr1 = LeakyReLU(alpha=0.2)(c1)\n",
        "    d1 = Dropout(0.25)(lr1)\n",
        "    c2 = Conv2D(64, kernel_size=3, strides=2, padding=\"same\")(d1)\n",
        "    zp1 = ZeroPadding2D(padding=((0, 1), (0, 1)))(c2)\n",
        "    bn1 = BatchNormalization(momentum=0.8)(zp1)\n",
        "    lr2 = LeakyReLU(alpha=0.2)(bn1)\n",
        "    d2 = Dropout(0.25)(lr2)\n",
        "    c3 = Conv2D(128, kernel_size=3, strides=2, padding=\"same\")(d2)\n",
        "    bn2 = BatchNormalization(momentum=0.8)(c3)\n",
        "    lr3 = LeakyReLU(alpha=0.2)(bn2)\n",
        "    d3 = Dropout(0.25)(lr3)\n",
        "    c4 = Conv2D(256, kernel_size=3, strides=1, padding=\"same\")(d3)\n",
        "    bn3 = BatchNormalization(momentum=0.8)(c4)\n",
        "    lr4 = LeakyReLU(alpha=0.2)(bn3)\n",
        "    d4 = Dropout(0.25)(lr4)\n",
        "    f = Flatten()(d4)\n",
        "    concat = Concatenate()([f, label])\n",
        "    hid = Dense(512, activation='relu')(concat)\n",
        "    out = Dense(1, activation='sigmoid')(concat)\n",
        "    return Model([img, label], out)\n",
        "\n",
        "  \n",
        "  def load_xrays(self, epochs=100, batch_size=1000, save_interval=20):\n",
        "    (img_x, img_y) = 256, 256\n",
        "    train_path = '/content/drive/MyDrive/xray GAN/xray14/'\n",
        "    data_path = 'data_entry.csv'\n",
        "\n",
        "    classes = ['Effusion', 'Emphysema', 'Cardiomegaly','Mass']\n",
        "    num_classes = len(classes)\n",
        "    img_folders = { 'images_001/', 'images_002/', 'images_003/', 'images_005/', \n",
        "                 'images_008/', 'images_011/', 'images_006/', 'images_007/', \n",
        "                 'images_004/', 'images_009/', 'images_010/', 'images_012/'}\n",
        "\n",
        "    # Load training data\n",
        "    dataTrain = pd.read_csv(train_path + data_path)\n",
        "\n",
        "    x_train = []\n",
        "    y_train = []\n",
        "\n",
        "    lb = preprocessing.LabelEncoder()#Binarizer()\n",
        "    lb.fit(classes)\t\n",
        "\n",
        "    count = 0\n",
        "    for index, row in dataTrain.iterrows():\n",
        "      for folder in img_folders:\n",
        "        label = row[\"Finding Labels\"]\n",
        "        if label not in classes:\n",
        "          continue\n",
        "        img1 = train_path + folder + \"images/\" + row[\"Image Index\"]\n",
        "        if not osp.exists(img1):\n",
        "          continue\n",
        "        #imgplot = plt.imshow(img1)\n",
        "        image1 = cv2.imread(img1)  # Image.open(img).convert('L')\n",
        "        image1 = image1[:, :, 0]\n",
        "        arr1 = cv2.resize(image1, (img_x, img_y))\n",
        "        arr1 = arr1.astype('float32')\n",
        "        arr1 /= 255.0\n",
        "        arr1 = arr1 - np.mean(arr1)\n",
        "        \n",
        "        x_train.append(arr1)\n",
        "        y_train.append(label)\n",
        "        #y_train.append(lb.transform([row[\"Finding Labels\"]]).flatten().T)\n",
        "      count += 1\n",
        "\n",
        "    print(\"shape of x train: {}\".format(len(x_train)))\n",
        "    x_train = np.asarray(x_train)\n",
        "    y_train = np.asarray(y_train)\n",
        "    x_train = x_train.reshape(count, img_y, img_x, 1)\n",
        "    #y_train = y_train.reshape(count, num_classes)\n",
        "    #print(\"Y SHAPE BEFORE RESHAPING: {}\".format(y_train.shape))\n",
        "    y_train = y_train.reshape(-1, 1)\n",
        "    #print(\"Y SHAPE: {}\".format(y_train.shape))\n",
        "\n",
        "    valid = np.ones((batch_size, 1))\n",
        "    fake = np.zeros((batch_size, 1))\n",
        "\n",
        "    # new experience relay to avoid mode collapse\n",
        "    exp_replay = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "      # ---------------------\n",
        "      #  Train Discriminator\n",
        "      # ---------------------\n",
        "\n",
        "      # Select a random half batch of images\n",
        "      idx = np.random.randint(0, x_train.shape[0], batch_size)\n",
        "      imgs, labels = x_train[idx], y_train[idx]\n",
        "\n",
        "      # Sample noise as generator input\n",
        "      noise = np.random.normal(0, 1, (batch_size, 128))\n",
        "\n",
        "      # Generate a half batch of new images\n",
        "      gen_imgs = self.generator.predict([noise, labels])\n",
        "\n",
        "      # Train the discriminator\n",
        "      d_loss_real = self.discriminator.train_on_batch([imgs, labels], valid)\n",
        "      d_loss_fake = self.discriminator.train_on_batch([gen_imgs, labels], fake)\n",
        "\n",
        "      # relay stuff\n",
        "      noise_prop = 0.05\n",
        "      gene_labels = np.ones((batch_size, 1)) - np.random.uniform(low=0.0, high=0.1, size=(batch_size, 1))\n",
        "      flipped_idx = np.random.choice(np.arange(len(gene_labels)), size=int(noise_prop*len(gene_labels)))\n",
        "      gene_labels[flipped_idx] = 1 - gene_labels[flipped_idx]\n",
        "    \n",
        "      # Store a random point for experience replay\n",
        "      r_idx = np.random.randint(batch_size)\n",
        "      exp_replay.append([gen_imgs[r_idx], labels[r_idx], gene_labels[r_idx]])\n",
        "      \n",
        "      if len(exp_replay) == batch_size:\n",
        "        generated_images = np.array([p[0] for p in exp_replay])\n",
        "        labels = np.array([p[1] for p in exp_replay])\n",
        "        gene_labels = np.array([p[2] for p in exp_replay])\n",
        "        expprep_loss_gene = discriminator.train_on_batch([generated_images, labels], gene_labels)\n",
        "        exp_replay = []\n",
        "        break\n",
        "    \n",
        "      d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "      # ---------------------\n",
        "      #  Train Generator\n",
        "      # ---------------------\n",
        "\n",
        "      # Condition on labels\n",
        "      sampled_labels = np.random.randint(0, 5, batch_size).reshape(-1, 1)\n",
        "\n",
        "      # Train the generator\n",
        "      g_loss = self.combined.train_on_batch([noise, sampled_labels], valid)\n",
        "\n",
        "      # Plot the progress\n",
        "      print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
        "\n",
        "      # If at save interval => save generated image samples\n",
        "      #if epoch % save_interval == 0:\n",
        "          #self.sample_images(epoch)\n",
        "\n",
        "  def sample_images(self, epoch):\n",
        "    r, c = 5, 5\n",
        "    noise = np.random.normal(0, 1, (r * c, 128))\n",
        "    sampled_labels = np.arange(0, 5).reshape(-1, 1)\n",
        "\n",
        "    gen_imgs = self.generator.predict([noise, sampled_labels])\n",
        "\n",
        "    # Rescale images 0 - 1\n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "    fig, axs = plt.subplots(r, c)\n",
        "    cnt = 0\n",
        "    for i in range(r):\n",
        "      for j in range(c):\n",
        "        axs[i,j].imshow(gen_imgs[cnt,:,:,0], cmap='gray')\n",
        "        axs[i,j].set_title(\"Digit: %d\" % sampled_labels[cnt])\n",
        "        axs[i,j].axis('off')\n",
        "        cnt += 1\n",
        "    fig.savefig(train_path + \"images/%d.png\" % epoch)\n",
        "    plt.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VF1jwJKAqfUe"
      },
      "source": [
        "# running CGAN\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JpD0jjYfqgVM",
        "outputId": "ac8c8c26-da1c-4708-8bb1-26c084acac37"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "  cgan = CGAN()\n",
        "  cgan.load_xrays(epochs=100, batch_size=1000, save_interval=20)\n",
        "  cgan.generator.save('models/gen.h5')\n",
        "  cgan.discriminator.save('models/disc.h5')\n",
        "  # Generate one-hot-encoded labels\n",
        "  # prepare label binarizer\n",
        "\n",
        "  lb = preprocessing.LabelEncoder()#Binarizer()\n",
        "\n",
        "  classes = ['Effusion', 'Emphysema', 'Cardiomegaly','Mass']\n",
        "\n",
        "  OHE_labels = lb.fit_transform(classes)\n",
        "\n",
        "  # at the end, loop per class, per 1000 images\n",
        "  cnt = 0\n",
        "  fig, ax = plt.subplots()\n",
        "  for label in OHE_labels:\n",
        "    for num in range(1):\n",
        "      nlab = np.asarray([label]).reshape(-1, 1)\n",
        "      noise1 = np.random.normal(0, 1, (1, 128))#cgan.latent_dim))\n",
        "      #noise1 = np.zeros((1, 10000))\n",
        "      #labels1 = np.tile(labels, 1000)\n",
        "      img = cgan.generator.predict([noise1, nlab])#labels1])\n",
        "      plt.imshow(img[cnt,:,:,0], cmap='gray')\n",
        "            #cnt+=1\n",
        "      fig.savefig( \"images-strong-conv/\" + str(label) + \"-\" + str(num) + \".png\")\n",
        "      plt.clf()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_23 (Dense)             (None, 131072)            16908288  \n",
            "_________________________________________________________________\n",
            "reshape_7 (Reshape)          (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_21 (UpSampling (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_60 (Conv2D)           (None, 64, 64, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_45 (Batc (None, 64, 64, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_28 (Activation)   (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_22 (UpSampling (None, 128, 128, 128)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_61 (Conv2D)           (None, 128, 128, 64)      73792     \n",
            "_________________________________________________________________\n",
            "batch_normalization_46 (Batc (None, 128, 128, 64)      256       \n",
            "_________________________________________________________________\n",
            "activation_29 (Activation)   (None, 128, 128, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_62 (Conv2D)           (None, 128, 128, 32)      18464     \n",
            "_________________________________________________________________\n",
            "batch_normalization_47 (Batc (None, 128, 128, 32)      128       \n",
            "_________________________________________________________________\n",
            "activation_30 (Activation)   (None, 128, 128, 32)      0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_23 (UpSampling (None, 256, 256, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_63 (Conv2D)           (None, 256, 256, 1)       289       \n",
            "_________________________________________________________________\n",
            "activation_31 (Activation)   (None, 256, 256, 1)       0         \n",
            "=================================================================\n",
            "Total params: 17,149,313\n",
            "Trainable params: 17,148,865\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n",
            "shape of x train: 8079\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-9b2d60e4b4f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mcgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mcgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_xrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mcgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'models/gen.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mcgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'models/disc.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-cf3455a1d159>\u001b[0m in \u001b[0;36mload_xrays\u001b[0;34m(self, epochs, batch_size, save_interval)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m     \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;31m#y_train = y_train.reshape(count, num_classes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Y SHAPE BEFORE RESHAPING: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 529465344 into shape (112120,256,256,1)"
          ]
        }
      ]
    }
  ]
}